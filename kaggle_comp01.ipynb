{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Kaggle Competition](https://www.kaggle.com/c/ga-customer-revenue-prediction/data): Google Analytics Customer Revenue Prediction\n",
    "Predict how much GStore customers will spend  \n",
    "**innogyDSGuild**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "#random.seed(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & clean datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read function\n",
    "Credit: https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(csv_path='data/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean function\n",
    "Credit: https://www.kaggle.com/ogakulov/feature-engineering-step-by-step  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(raw_df, copy=False):\n",
    "    \n",
    "    if copy:\n",
    "        raw_df = raw_df.copy()\n",
    "    \n",
    "    # Drop columns with just one value or all unknown\n",
    "    cols_to_drop = [col for col in raw_df.columns if raw_df[col].nunique() == 1]\n",
    "    raw_df.drop(columns = cols_to_drop, inplace=True)\n",
    "\n",
    "    # Drop campaign colum as it only has one non-null value\n",
    "    raw_df.drop(['trafficSource.campaign'], axis=1, inplace=True)\n",
    "    \n",
    "    # Rename long column names to be more concise\n",
    "    raw_df.rename(columns={col_name: col_name.split('.')[-1] for col_name in raw_df.columns}, inplace = True)\n",
    "    \n",
    "    # Fill transactionRevenue with zeros and convert its type to numeric for train data\n",
    "    try:\n",
    "        raw_df['transactionRevenue'].fillna(0, inplace=True)\n",
    "        raw_df['transactionRevenue'] = pd.to_numeric(raw_df['transactionRevenue'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    # convert timestamp to DateTime\n",
    "    raw_df[\"visitStartTime_POSIX\"] = raw_df[\"visitStartTime\"].copy() # backup\n",
    "    raw_df[\"visitStartTime\"] = raw_df.visitStartTime.apply(pd.Timestamp, unit='s')\n",
    "    \n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "raw_df_train = load_df(\"data/train.csv\", nrows=100000)\n",
    "df_train = clean_df(raw_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "raw_df_test  = load_df(\"data/test.csv\", nrows=1000)\n",
    "df_test      = clean_df(raw_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or alternatively use some of the training data as testing data, to make verification easier without uploading to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitorIds = list(set(df_train.fullVisitorId))\n",
    "visitorIds.sort()\n",
    "random.shuffle(visitorIds)\n",
    "test_fraction = 0.3\n",
    "testIds  = visitorIds[:int(test_fraction * len(visitorIds))]\n",
    "trainIds = visitorIds[int(test_fraction * len(visitorIds)):]\n",
    "\n",
    "df_train_total = df_train.copy()\n",
    "df_test  = df_train[df_train.fullVisitorId.isin(testIds) ].copy()\n",
    "df_train = df_train[df_train.fullVisitorId.isin(trainIds)].copy()\n",
    "\n",
    "# compute total revenue for test data\n",
    "logRevenue = df_test[[\"transactionRevenue\",\"fullVisitorId\"]].groupby(\"fullVisitorId\").sum()\n",
    "logRevenue[\"LogRevenue\"] = np.log(logRevenue[\"transactionRevenue\"] + 1)\n",
    "logRevenue.drop(columns=\"transactionRevenue\", inplace=True)\n",
    "\n",
    "# backup true revenue\n",
    "df_test[\"trueTransactionRevenue\"] = df_test.transactionRevenue.copy()\n",
    "df_test[\"transactionRevenue\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)\n",
    "Check also https://www.kaggle.com/captcalculator/a-very-extensive-gstore-exploratory-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check columns of test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%-25s | %-10s | %-10s\" % (\"Column\", \"Train\", \"Test\"))\n",
    "print(51*\"-\")\n",
    "for s in set(df_train.columns).union(set(df_test.columns)):\n",
    "    print(\"%-25s | %10s | %10s\" % (s, s in df_train.columns, s in df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Some ideas:\n",
    "* Convert time to users local time\n",
    "* Use geographic information to add external data sources, like economic wealth of the country ([May not be allowed](https://www.kaggle.com/c/ga-customer-revenue-prediction/discussion/66425 \"On The Use of External Data\"))\n",
    "* Add past total revenue, past average revenue per visit, time since last revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find timezone offset\n",
    "Trivially by finding the hour of the day with minimum activity in each region and computing the offset to United Kingdom.\n",
    "Could be done much more accurate with the region/country/metro/city information with additional data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_min = {}\n",
    "for region in set(df_train_total.region):\n",
    "    mask = df_train_total.region == region\n",
    "    hist, bin_edges = np.histogram(df_train_total.visitStartTime[mask].dt.hour, bins=24, range=(0,24))\n",
    "    region_min[region] = bin_edges[hist.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_train.country == \"United States\"\n",
    "plt.hist(df_train.visitStartTime[mask].dt.hour, bins=24, range=(0,24))\n",
    "plt.title(\"Visits by hour of day for US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict *transactionRevenue*\n",
    "For the moment, fill with random values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "median = df_train.transactionRevenue.median()\n",
    "mean   = df_train.transactionRevenue.mean()\n",
    "std    = df_train.transactionRevenue.std()\n",
    "df_test[\"transactionRevenue\"] = [random.randint(max(0, int(median-std)), int(median+std)) for i in range(df_test.shape[0])]\n",
    "median, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"transactionRevenue\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try [SGDRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor) from scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier with hour of day of the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "clf.fit(df_train.visitStartTime.dt.hour.values.reshape(-1, 1), df_train.transactionRevenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"transactionRevenue\"] = clf.predict(df_test.visitStartTime.dt.hour.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulate revenue per fullVisitorID and write output for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = df_test[[\"transactionRevenue\",\"fullVisitorId\"]].groupby(\"fullVisitorId\").sum()\n",
    "prediction[\"PredictedLogRevenue\"] = np.log(prediction[\"transactionRevenue\"] + 1)\n",
    "prediction.drop(columns=\"transactionRevenue\", inplace=True)\n",
    "prediction.head()\n",
    "prediction.to_csv(\"prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute RMSD to true data if possible"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logRevenue.sort_index(axis=\"columns\", inplace=True)\n",
    "prediction.sort_index(axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD = ((prediction.PredictedLogRevenue - logRevenue.LogRevenue)**2).mean()**0.5\n",
    "print(\"RMSD = %.4f\" % RMSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the transaction revenue to be zero always results in an RMSD of less than 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check where we are on the [public leaderboard from kaggle](https://www.kaggle.com/c/ga-customer-revenue-prediction/leaderboard)\n",
    "Download up to date data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourScore = RMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = pd.read_csv(\"data/publicleaderboarddata.zip\")\n",
    "best = leaderboard[[\"TeamId\", \"Score\"]].groupby([\"TeamId\"]).min()\n",
    "best.sort_values(by=\"Score\", ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourRank = (best.Score <= ourScore).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best.Score.values, \".\")\n",
    "plt.plot(2*[ourRank], plt.ylim(), \"r\")\n",
    "plt.plot(plt.xlim(), 2*[ourScore], \"r\")\n",
    "plt.ylim(1, 5)\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "print(\"Our Rank : %d/%d (best %2.1f%%)\" % (ourRank, best.shape[0], 100*ourRank/best.shape[0]))\n",
    "print(\"Our Score: %.4f\" % ourScore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
